---
title: "stan-posterior-estimation"
author: "Yuria Utsumi"
date: "2025-05-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup, include=FALSE}
# run the next line if you already have rstan installed
# remove.packages(c("StanHeaders", "rstan"))

install.packages("rstan", repos = c('https://stan-dev.r-universe.dev', getOption("repos")))
```

```{r setup, include=FALSE}
example(stan_model, package = "rstan", run.dontrun = TRUE)
```

## stan posterior estimation

Stan has various samplers and inference algorithms to estimate the posterior. It is known for No-U Turn sampler (NUTS) a variant of Hamiltonian Markov Chain, which is a MCMC based algorithm that chooses efficient step sizes. However, there are other MCMC samplers, as well as Automatic Differentiation Variational Inference, which approximates the posterior using simpler distributions. This is faster than MCMC based methods but may give approximate solutions. This is often used to set prior before using, e.g. NUTS. 

Note: Code was generated with the help of GPT-4o.

```{r pressure, echo=FALSE}
# Load necessary libraries
library(rstan)
library(bayesplot)

# Set seed for reproducibility
set.seed(123)

# Define a simple Bayesian model in Stan
stan_model_code <- "
data {
  int<lower=0> N; // number of data points
  vector[N] y;    // observed data
}
parameters {
  real mu;        // mean parameter
  real<lower=0> sigma; // standard deviation parameter
}
model {
  y ~ normal(mu, sigma); // likelihood
  mu ~ normal(0, 10);    // prior for mu
  sigma ~ cauchy(0, 5);  // prior for sigma
}
"

# Compile the Stan model
stan_model <- stan_model(model_code = stan_model_code)

# Generate synthetic data
N <- 100
y <- rnorm(N, mean = 5, sd = 2)

# Prepare data for Stan
stan_data <- list(N = N, y = y)

# Run NUTS sampler
nuts_fit <- stan(model = stan_model, data = stan_data, 
                 iter = 2000, chains = 4, 
                 control = list(adapt_delta = 0.95), 
                 warmup = 1000, refresh = 0)

# Run ADVI sampler
advi_fit <- stan(model = stan_model, data = stan_data, 
                 iter = 2000, chains = 4, 
                 algorithm = "meanfield", 
                 refresh = 0)

# Run MCMC sampler
mcmc_fit <- stan(model = stan_model, data = stan_data, 
                 iter = 2000, chains = 4, 
                 control = list(adapt_delta = 0.95), 
                 warmup = 1000, refresh = 0)

# Extract parameter estimates
nuts_samples <- extract(nuts_fit)
advi_samples <- extract(advi_fit)
mcmc_samples <- extract(mcmc_fit)

# Compare parameter estimates
nuts_mu_est <- mean(nuts_samples$mu)
advi_mu_est <- mean(advi_samples$mu)
mcmc_mu_est <- mean(mcmc_samples$mu)

nuts_sigma_est <- mean(nuts_samples$sigma)
advi_sigma_est <- mean(advi_samples$sigma)
mcmc_sigma_est <- mean(mcmc_samples$sigma)

# Print parameter estimates
cat("Parameter Estimates:\n")
cat("NUTS: mu =", nuts_mu_est, ", sigma =", nuts_sigma_est, "\n")
cat("ADVI: mu =", advi_mu_est, ", sigma =", advi_sigma_est, "\n")
cat("MCMC: mu =", mcmc_mu_est, ", sigma =", mcmc_sigma_est, "\n")

# Plot trace plots for visual comparison
par(mfrow = c(3, 2))
plot(nuts_fit, pars = c("mu", "sigma"), main = "NUTS Trace Plots")
plot(advi_fit, pars = c("mu", "sigma"), main = "ADVI Trace Plots")
plot(mcmc_fit, pars = c("mu", "sigma"), main = "MCMC Trace Plots")

# Compare mixing times (effective sample size)
nuts_ess <- summary(nuts_fit)$summary[, "n_eff"]
advi_ess <- summary(advi_fit)$summary[, "n_eff"]
mcmc_ess <- summary(mcmc_fit)$summary[, "n_eff"]

cat("\nEffective Sample Sizes:\n")
cat("NUTS: mu =", nuts_ess[1], ", sigma =", nuts_ess[2], "\n")
cat("ADVI: mu =", advi_ess[1], ", sigma =", advi_ess[2], "\n")
cat("MCMC: mu =", mcmc_ess[1], ", sigma =", mcmc_ess[2], "\n")
```
